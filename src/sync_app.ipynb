{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test task\n",
    "Implement a program that synchronizes two folders: source and\n",
    "replica. The program should maintain a full, identical copy of source\n",
    "folder at replica folder. Solve the test task by writing a program in\n",
    "Python.\n",
    "\n",
    "- Synchronization must be one-way: after the synchronization content of the\n",
    "  replica folder should be modified to exactly match content of the source\n",
    "  folder;\n",
    "  Synchronization should be performed periodically;\n",
    "\n",
    "- File creation/copying/removal operations should be logged to a file and to the\n",
    "  console output;\n",
    "  Folder paths, synchronization interval and log file path should be provided\n",
    "  using the command line arguments;\n",
    "  It is undesirable to use third-party libraries that implement folder\n",
    "  synchronization;\n",
    "  \n",
    "- It is allowed (and recommended) to use external libraries implementing other\n",
    "  well-known algorithms. For example, there is no point in implementing yet\n",
    "  another function that calculates MD5 if you need it for the task â€“ it is perfectly\n",
    "  acceptable to use a third-party (or built-in) library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries and external functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import time\n",
    "import json\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate_fileops import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default configuration\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source': '../raw/source_folder',\n",
       " 'replica': '../replica_folder',\n",
       " 'log': '../.log',\n",
       " 'log_file': '/sync_log.txt',\n",
       " 'sync_interval': 60}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../cfg/config.json') as f:\n",
    "    config = json.load(f)\n",
    "    \n",
    "print(f'Default configuration')\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = config['source']\n",
    "replica_folder = config['replica']\n",
    "log_folder = config['log']\n",
    "log_file_path = log_folder + config['log_file']\n",
    "sync_interval = config['sync_interval'] # this is in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Synchronization of two folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_md5(file_path: str) -> hashlib.md5:\n",
    "    \"\"\"Calculate the MD5 hash of a file\n",
    "\n",
    "    Args:\n",
    "        file_path (str): file path\n",
    "\n",
    "    Returns:\n",
    "        _type_: hash_md5\n",
    "    \"\"\"\n",
    "    \n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def copy_file(source_file: str, replica_file: str):\n",
    "    \"\"\"Copy file from source to replica\n",
    "\n",
    "    Args:\n",
    "        source_file (str): source file path\n",
    "        replica_file (str): replaica file path\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(source_file, 'rb') as src_file:\n",
    "        with open(replica_file, 'wb') as dest_file:\n",
    "            for chunk in iter(lambda: src_file.read(4096), b\"\"):\n",
    "                dest_file.write(chunk)\n",
    "\n",
    "def create_folders():\n",
    "    \"\"\"Create folders if they don't exist\n",
    "    \"\"\"\n",
    "    if not os.path.exists(source_folder):\n",
    "        os.makedirs(source_folder)\n",
    "\n",
    "    if not os.path.exists(replica_folder):\n",
    "        os.makedirs(replica_folder)\n",
    "\n",
    "    if not os.path.exists(log_folder):\n",
    "        os.makedirs(log_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synchronize_folders(run_sync: bool = True):\n",
    "    \"\"\"Sync folders and log each addition, modification and removal of files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create source folder, replica and log folders if they doesn't exist\n",
    "    create_folders()\n",
    "    \n",
    "    # Tracking replica folder\n",
    "    replica_state = {}\n",
    "    \n",
    "    current_time = time.ctime()\n",
    "    \n",
    "    print(f\"[{current_time}] Syncing {source_folder} and {replica_folder} folders\")\n",
    "    \n",
    "    print(f\"[{current_time}] Sync interval: {sync_interval} seconds\")\n",
    "    \n",
    "    print(f\"[{current_time}] Logging to {log_file_path}\")\n",
    "    \n",
    "    with open(log_file_path, \"w\") as log_file:\n",
    "        log_file.write(f\"[{current_time}] Syncing {source_folder} and {replica_folder} folders\\n\")\n",
    "        log_file.write(f\"[{current_time}] Sync interval: {sync_interval} seconds\\n\")\n",
    "    \n",
    "    while run_sync:\n",
    "        for root, dirs, files in os.walk(source_folder):\n",
    "            for file_name in files:\n",
    "                source_file_path = os.path.join(root, file_name).replace('\\\\', '/')\n",
    "                replica_file_path = os.path.join(replica_folder, os.path.relpath(source_file_path, source_folder)).replace('\\\\', '/')\n",
    "\n",
    "                # MD5 hash of source file\n",
    "                source_file_md5 = calculate_md5(source_file_path)\n",
    "\n",
    "                # Verify here\n",
    "                if replica_file_path in replica_state:\n",
    "                    replica_file_md5 = replica_state[replica_file_path]\n",
    "                else:\n",
    "                    replica_file_md5 = \"\"\n",
    "\n",
    "                # checkinfg if file is new or has been modified\n",
    "                if source_file_md5 != replica_file_md5:\n",
    "                    copy_file(source_file_path, replica_file_path)\n",
    "                    replica_state[replica_file_path] = source_file_md5\n",
    "                    current_time = time.ctime()\n",
    "                    print(f\"[{current_time}] Copied: {source_file_path} -> {replica_file_path}\")\n",
    "                    with open(log_file_path, \"a\") as log_file:\n",
    "                        log_file.write(f\"[{current_time}] Copied: {source_file_path} -> {replica_file_path}\\n\")\n",
    "\n",
    "        # Check for files to delete in replica folder\n",
    "        for replica_file_path, replica_file_md5 in list(replica_state.items()):\n",
    "            source_file_path = os.path.join(source_folder, os.path.relpath(replica_file_path, replica_folder))\n",
    "            # deletes in replica folder if it was deleted in source\n",
    "            if not os.path.exists(source_file_path):\n",
    "                os.remove(replica_file_path)\n",
    "                del replica_state[replica_file_path]\n",
    "                current_time = time.ctime()\n",
    "                print(f\"[{current_time}] Deleted: {replica_file_path}\")\n",
    "                with open(log_file_path, \"a\") as log_file:\n",
    "                    log_file.write(f\"[{time.ctime()}] Deleted: {replica_file_path}\\n\")\n",
    "\n",
    "        time.sleep(sync_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thu Nov  9 08:46:23 2023] File operations started!\n",
      "[Thu Nov  9 08:46:23 2023] Syncing ../raw/source_folder and ../replica_folder folders\n",
      "[Thu Nov  9 08:46:23 2023] Sync interval: 60 seconds\n",
      "[Thu Nov  9 08:46:23 2023] Logging to ../.log/sync_log.txt\n",
      "[Thu Nov  9 08:48:23 2023] Copied: ../raw/source_folder/dummy_text.txt -> ../replica_folder/dummy_text.txt\n",
      "[Thu Nov  9 08:49:23 2023] Copied: ../raw/source_folder/dummy_text.txt -> ../replica_folder/dummy_text.txt\n",
      "[Thu Nov  9 08:49:23 2023] Copied: ../raw/source_folder/ratings_matrix.csv -> ../replica_folder/ratings_matrix.csv\n",
      "[Thu Nov  9 08:50:23 2023] Deleted: ../replica_folder/ratings_matrix.csv\n",
      "[Thu Nov  9 08:51:23 2023] Copied: ../raw/source_folder/ratings_matrix.csv -> ../replica_folder/ratings_matrix.csv\n",
      "[Thu Nov  9 08:52:23 2023] File operations finished!\n",
      "[Thu Nov  9 08:52:23 2023] Copied: ../raw/source_folder/Veeam-Logo.png -> ../replica_folder/Veeam-Logo.png\n",
      "[Thu Nov  9 08:56:36 2023] Stopping synchronization thread...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    # Run the synchronization in a separate thread\n",
    "    sync_thread = threading.Thread(target=synchronize_folders, daemon=False)\n",
    "\n",
    "    # Simulate file operations in a separate thread\n",
    "    sim_fileops_thread = threading.Thread(target=simulate_file_operations, daemon=False)\n",
    "\n",
    "    # Start threads\n",
    "    sync_thread.start()\n",
    "    sim_fileops_thread.start()\n",
    "\n",
    "    # Stops the folders synchronization\n",
    "    input(f\"Press Enter to finish folder synchronization!\")\n",
    "    run_sync = False\n",
    "\n",
    "    # Logging the end of the synchronization application\n",
    "    current_time = time.ctime()\n",
    "    print(f\"[{current_time}] Stopping synchronization thread...\")\n",
    "    with open(log_file_path, \"a\") as log_file: # append to log file\n",
    "        log_file.write(f\"[{current_time}] Stopping folders synchronization.\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    current_time = time.ctime()\n",
    "    print(f\"{[current_time]} Error: {e}\")\n",
    "    with open(log_file_path, \"a\") as log_file: # append exception to log file\n",
    "        log_file.write(f\"{[current_time]} Error: {e}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standalone version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import argparse\n",
    "\n",
    "def calculate_md5(file_path: str) -> hashlib.md5:\n",
    "    \"\"\"Calculate the MD5 hash of a file\n",
    "\n",
    "    Args:\n",
    "        file_path (str): file path\n",
    "\n",
    "    Returns:\n",
    "        _type_: hash_md5\n",
    "    \"\"\"\n",
    "    \n",
    "    hash_md5 = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "            hash_md5.update(chunk)\n",
    "    return hash_md5.hexdigest()\n",
    "\n",
    "def copy_file(source_file: str, replica_file: str):\n",
    "    \"\"\"Copy file from source to replica\n",
    "\n",
    "    Args:\n",
    "        source_file (str): source file path\n",
    "        replica_file (str): replaica file path\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(source_file, 'rb') as src_file:\n",
    "        with open(replica_file, 'wb') as dest_file:\n",
    "            for chunk in iter(lambda: src_file.read(4096), b\"\"):\n",
    "                dest_file.write(chunk)\n",
    "\n",
    "def create_folders(source_folder: str, replica_folder: str, log_folder: str):\n",
    "    \"\"\"Create folders if they don't exist\n",
    "    \"\"\"\n",
    "    if not os.path.exists(source_folder):\n",
    "        os.makedirs(source_folder)\n",
    "\n",
    "    if not os.path.exists(replica_folder):\n",
    "        os.makedirs(replica_folder)\n",
    "\n",
    "    if not os.path.exists(log_folder):\n",
    "        os.makedirs(log_folder)\n",
    "\n",
    "def synchronize_folders(source_folder: str, replica_folder: str, log_file_path: str, sync_interval: int, run_sync: bool = True):\n",
    "    \"\"\"Sync folders and log each addition, modification and removal of files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Tracking replica folder\n",
    "    replica_state = {}\n",
    "    \n",
    "    current_time = time.ctime()\n",
    "    \n",
    "    print(f\"[{current_time}] Syncing {source_folder} and {replica_folder} folders\")\n",
    "    \n",
    "    print(f\"[{current_time}] Sync interval: {sync_interval} seconds\")\n",
    "    \n",
    "    print(f\"[{current_time}] Logging to {log_file_path}\")\n",
    "    \n",
    "    with open(log_file_path, \"w\") as log_file:\n",
    "        log_file.write(f\"[{current_time}] Syncing {source_folder} and {replica_folder} folders\\n\")\n",
    "        log_file.write(f\"[{current_time}] Sync interval: {sync_interval} seconds\\n\")\n",
    "    \n",
    "    while run_sync:\n",
    "        for root, dirs, files in os.walk(source_folder):\n",
    "            for file_name in files:\n",
    "                source_file_path = os.path.join(root, file_name).replace('\\\\', '/')\n",
    "                replica_file_path = os.path.join(replica_folder, os.path.relpath(source_file_path, source_folder)).replace('\\\\', '/')\n",
    "\n",
    "                # MD5 hash of source file\n",
    "                source_file_md5 = calculate_md5(source_file_path)\n",
    "\n",
    "                # Verify here\n",
    "                if replica_file_path in replica_state:\n",
    "                    replica_file_md5 = replica_state[replica_file_path]\n",
    "                else:\n",
    "                    replica_file_md5 = \"\"\n",
    "\n",
    "                # checkinfg if file is new or has been modified\n",
    "                if source_file_md5 != replica_file_md5:\n",
    "                    copy_file(source_file_path, replica_file_path)\n",
    "                    replica_state[replica_file_path] = source_file_md5\n",
    "                    current_time = time.ctime()\n",
    "                    print(f\"[{current_time}] Copied: {source_file_path} -> {replica_file_path}\")\n",
    "                    with open(log_file_path, \"a\") as log_file:\n",
    "                        log_file.write(f\"[{current_time}] Copied: {source_file_path} -> {replica_file_path}\\n\")\n",
    "\n",
    "        # Check for files to delete in replica folder\n",
    "        for replica_file_path, replica_file_md5 in list(replica_state.items()):\n",
    "            source_file_path = os.path.join(source_folder, os.path.relpath(replica_file_path, replica_folder))\n",
    "            # deletes in replica folder if it was deleted in source\n",
    "            if not os.path.exists(source_file_path):\n",
    "                os.remove(replica_file_path)\n",
    "                del replica_state[replica_file_path]\n",
    "                current_time = time.ctime()\n",
    "                print(f\"[{current_time}] Deleted: {replica_file_path}\")\n",
    "                with open(log_file_path, \"a\") as log_file:\n",
    "                    log_file.write(f\"[{time.ctime()}] Deleted: {replica_file_path}\\n\")\n",
    "\n",
    "        time.sleep(sync_interval)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    # Parse arguments: source, replica, log and sync_interval\n",
    "    parser = argparse.ArgumentParser(description='Sync folders')\n",
    "    parser.add_argument('--source', type=str, help='Source folder')\n",
    "    parser.add_argument('--replica', type=str, help='Replica folder')\n",
    "    parser.add_argument('--log', type=str, help='Log folder')\n",
    "    parser.add_argument('--interval', type=int, help='Sync interval in seconds')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.source:\n",
    "        source_folder = args.source\n",
    "\n",
    "    if args.replica:\n",
    "        replica_folder = args.replica\n",
    "\n",
    "    if args.log:\n",
    "        log_folder = args.log\n",
    "\n",
    "    if args.interval:\n",
    "        sync_interval = args.interval\n",
    "\n",
    "    # Create source folder, replica and log folders if they doesn't exist\n",
    "    create_folders(source_folder, replica_folder, log_folder)\n",
    "    \n",
    "    try:\n",
    "\n",
    "        log_file_path = log_folder + f'/sync_log_{time.ctime()}.txt'.replace(' ', '_')\n",
    "\n",
    "        # Synchronization\n",
    "        synchronize_folders(source_folder, replica_folder, log_file_path, sync_interval)\n",
    "\n",
    "        # Logging the end of the synchronization application\n",
    "        current_time = time.ctime()\n",
    "        print(f\"[{current_time}] Stopping synchronization thread...\")\n",
    "        with open(log_file_path, \"a\") as log_file: # append to log file\n",
    "            log_file.write(f\"[{current_time}] Stopping folders synchronization.\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # log exception if not KeyboardInterrupt\n",
    "        if not isinstance(e, KeyboardInterrupt):\n",
    "            current_time = time.ctime()\n",
    "            print(f\"{[current_time]} Error: {e}\")\n",
    "            with open(log_file_path, \"a\") as log_file: # append exception to log file\n",
    "                log_file.write(f\"{[current_time]} Error: {e}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **SETUP:**\n",
    "    - ``sync_app.py`` is run with the following params:\n",
    "        - ``source_folder``: [``../raw/source_folder``](../raw/source_folder)\n",
    "        - ``replica_folder``: [``../replica_folder``](../replica_folder)\n",
    "        - ``log_file``: [``../.log/sync_log.txt``](../.log/sync_log.txt)\n",
    "        - ``sync_interval``: 60 seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **TESTS:**\n",
    "    - File addition, modification and removal will be tested.\n",
    "    - Blank file ``dummy_text.txt`` is copied to source_folder\n",
    "    - Dummy file ``dummy_text.txt`` is modified in ``source_folder`` by copying the content from ``dummy_text.txt`` in [``../raw/example_files/dummy_text-modify_1.txt``](../raw/example_files/dummy_text-modify_1.txt)\n",
    "    - This process will be repeated again with [``../raw/example_files/dummy_text-modify_2.txt``](../raw/example_files/dummy_text-modify_2.txt).\n",
    "    - The image file [``../raw/example_files/Veeam-Logo.png``](../raw/example_files/Veeam-Logo.png) will be copied to ``source_folder``.\n",
    "    - The CSV file [``../raw/example_files/ratings_matrix.csv``](../raw/example_files/ratings_matrix.csv) will be copied to ``source_folder``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **EXPECTED RESULTS:**\n",
    "    - It is expected that the ``dummy_text.txt`` file will be copied to [``../replica_folder``](../replica_folder) and removed from it if it no longer exists inside the ``source_folder``.\n",
    "\n",
    "    - Changes made to the ``dummy_text.txt`` file in ``source_folder`` will be reflected in the ``dummy_text.txt`` file in ``replica_folder``.\n",
    "\n",
    "    - It is expect that the log file will register the operation at [``../.log/sync_log.txt``](../.log/sync_log.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code created to simulate file operations in [``./simulate_fileops.py``](./simulate_fileops.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````python\n",
    "import shutil\n",
    "import time\n",
    "import os\n",
    "\n",
    "def simulate_file_operations():\n",
    "    \"\"\"Simulate file operations by copying files to the source folder and removing them after a certain time.\"\"\"\n",
    "    \n",
    "    source_folder = '../raw/source_folder'\n",
    "    example_files = '../raw/example_files'\n",
    "\n",
    "    # Sleep for 80 seconds\n",
    "    time.sleep(80)\n",
    "\n",
    "    # Copy dummy_text.txt\n",
    "    shutil.copy(os.path.join(example_files, 'dummy_text.txt'), source_folder)\n",
    "\n",
    "    # Sleep for 70 seconds\n",
    "    time.sleep(70)\n",
    "\n",
    "    # Copy modified dummy_text.txt\n",
    "    shutil.copy(os.path.join(example_files, 'dummy_text-modify_1.txt'), os.path.join(source_folder, 'dummy_text.txt'))\n",
    "\n",
    "    # Sleep for 15 seconds\n",
    "    time.sleep(15)\n",
    "\n",
    "    # Copy modified dummy_text.txt again\n",
    "    shutil.copy(os.path.join(example_files, 'dummy_text-modify_2.txt'), os.path.join(source_folder, 'dummy_text.txt'))\n",
    "\n",
    "    # Sleep for 5 seconds\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Copy ratings_matrix.csv\n",
    "    shutil.copy(os.path.join(example_files, 'ratings_matrix.csv'), source_folder)\n",
    "\n",
    "    # Sleep for 90 seconds\n",
    "    time.sleep(90)\n",
    "\n",
    "    # Copy ratings_matrix.csv again\n",
    "    shutil.copy(os.path.join(example_files, 'ratings_matrix.csv'), source_folder)\n",
    "\n",
    "    # Sleep for 20 seconds\n",
    "    time.sleep(20)\n",
    "\n",
    "    # Copy Veeam-Logo.png\n",
    "    shutil.copy(os.path.join(example_files, 'Veeam-Logo.png'), source_folder)\n",
    "\n",
    "    # Sleep for 10 seconds\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Remove Veeam-Logo.png\n",
    "    os.remove(os.path.join(source_folder, 'Veeam-Logo.png'))\n",
    "\n",
    "    # Sleep for 70 seconds\n",
    "    time.sleep(70)\n",
    "\n",
    "    # Copy Veeam-Logo.png again\n",
    "    shutil.copy(os.path.join(example_files, 'Veeam-Logo.png'), source_folder)\n",
    "\n",
    "if __name__ == \"__main\":\n",
    "    simulate_file_operations()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What could be improved:\n",
    "\n",
    "- Logging could be improved by using a logger object and be appropriatly handled by it since python has a built-in library for that.\n",
    "\n",
    "- The code could be improved by using a class to handle the syncronization process.\n",
    "\n",
    "- Testing: While I have tested the code enough to check that it works as expected, I haven't used any testing library to do so due to time constraints.\n",
    "\n",
    "- A GUI could be implemented to make it more user friendly.\n",
    "\n",
    "## Comments:\n",
    "\n",
    "- While as implementing I have noticed ways to optimize the code, I have decided to leave it as it is to show my thought process and how I have improved the code as I was implementing it.\n",
    "\n",
    "- This version should be considered as **working as required**, but not as a **final version** which, given more time, I could put more thought in it.\n",
    "\n",
    "- I have decided to use the ``os`` library to handle the file system operations which have most of the time been used in other projects I have done before and were enough for the job, but I have noticed that there is a library called ``shutil`` which could be used to handle the file system operations in a more efficient way. I have decided to not use it because a version **from scratch** could help me deliver a version as fast as possible due to more familiarity.\n",
    "\n",
    "- I haven't used any third-party library to handle the MD5 hash, but I have used the built-in library ``hashlib`` to do so.\n",
    "\n",
    "- I have chosen the Jupyter Notebook to write the code because it is a tool I am familiar which makes it easeir for me to use, showcase and illustrate my thought process.\n",
    "\n",
    "- I am aware that I could make everything using just linux commands like ``rsync`` and automate the process using cron, but I am more confortable with python code despite being familiar with many unix commands.\n",
    "\n",
    "## References:\n",
    "\n",
    "I have used the following references to help me implement the code:\n",
    "\n",
    "- Other projects made by myself where I needed to handle file system operations and multithreading.\n",
    "\n",
    "- [VERIFY MD5 / SHA256 Hash or Checksum on Linux - File Security (Ubuntu)](https://www.youtube.com/watch?v=uIIn6qVGOJQ) to review some concepts about MD5 hash and test it locally in my system.\n",
    "\n",
    "- [How To Detect File Changes with Python (and send notification)](https://www.youtube.com/watch?v=lVDajXJEpmg) - is totally different from what I have implemented but it helped me as a first concept.\n",
    "\n",
    "- [Python Documentation](https://docs.python.org/3/library/os.html) to check os documentation.\n",
    "\n",
    "- [Python Documentation](https://docs.python.org/3/library/hashlib.html) to check hashlib documentation.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
